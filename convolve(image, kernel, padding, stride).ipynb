{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] applying small_blur kernel\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'BORDER_CONST'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-254135011cdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] applying {} kernel\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernelName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mconvoleOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mopencvOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-254135011cdc>\u001b[0m in \u001b[0;36mconvolve\u001b[0;34m(image, kernel, padding, stride)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# size (i.e., width and height) are not reduced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkW\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyMakeBorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBORDER_CONST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# loop over the input image, \"sliding\" the kernel across\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'BORDER_CONST'"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from skimage.exposure import rescale_intensity\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def convolve(image, kernel, padding, stride):\n",
    "\t# grab the spatial dimensions of the image, along with\n",
    "\t# the spatial dimensions of the kernel\n",
    "\t(iH, iW) = image.shape[:2]\n",
    "\t(kH, kW) = kernel.shape[:2]\n",
    " \n",
    "\t# allocate memory for the output image, taking care to\n",
    "\t# \"pad\" the borders of the input image so the spatial\n",
    "\t# size (i.e., width and height) are not reduced\n",
    "\tpad = int((kW - 1) / 2)\n",
    "\timage = cv2.copyMakeBorder(image, pad, pad, pad, pad, cv2.BORDER_CONST, padding)\n",
    "\toutput = np.zeros((iH, iW), dtype=\"float32\")\n",
    "    # loop over the input image, \"sliding\" the kernel across\n",
    "\t# each (x, y)-coordinate from left-to-right and top to\n",
    "\t# bottom\n",
    "\tfor y in np.arange(pad, iH + pad):\n",
    "\t\tfor x in np.arange(pad, iW + pad):\n",
    "\t\t\t# extract the ROI of the image by extracting the\n",
    "\t\t\t# *center* region of the current (x, y)-coordinates\n",
    "\t\t\t# dimensions\n",
    "\t\t\tfor i in range(y-pad, y+pad+1, stride):\n",
    "\t\t\t\troi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    "\t\t\tfor j in range(x-pad, x+pad+1, stride):\n",
    "\t\t\t\troi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    " \n",
    "\t\t\t# perform the actual convolution by taking the\n",
    "\t\t\t# element-wise multiplicate between the ROI and\n",
    "\t\t\t# the kernel, then summing the matrix\n",
    "\t\t\tk = (roi * kernel).sum()\n",
    " \n",
    "\t\t\t# store the convolved value in the output (x,y)-\n",
    "\t\t\t# coordinate of the output image\n",
    "\t\t\toutput[y - pad, x - pad] = k\n",
    "            # rescale the output image to be in the range [0, 255]\n",
    "\toutput = rescale_intensity(output, in_range=(0, 255))\n",
    "\toutput = (output * 255).astype(\"uint8\")\n",
    " \n",
    "\t# return the output image\n",
    "\treturn output\n",
    "\n",
    "\n",
    "# construct average blurring kernels used to smooth an image\n",
    "smallBlur = np.ones((7, 7), dtype=\"float\") * (1.0 / (7 * 7))\n",
    "largeBlur = np.ones((21, 21), dtype=\"float\") * (1.0 / (21 * 21))\n",
    " \n",
    "# construct a sharpening filter\n",
    "sharpen = np.array((\n",
    "\t[0, -1, 0],\n",
    "\t[-1, 5, -1],\n",
    "\t[0, -1, 0]), dtype=\"int\")\n",
    "# construct the Laplacian kernel used to detect edge-like\n",
    "# regions of an image\n",
    "laplacian = np.array((\n",
    "\t[0, 1, 0],\n",
    "\t[1, -4, 1],\n",
    "\t[0, 1, 0]), dtype=\"int\")\n",
    " \n",
    "# construct the Sobel x-axis kernel\n",
    "sobelX = np.array((\n",
    "\t[-1, 0, 1],\n",
    "\t[-2, 0, 2],\n",
    "\t[-1, 0, 1]), dtype=\"int\")\n",
    " \n",
    "# construct the Sobel y-axis kernel\n",
    "sobelY = np.array((\n",
    "\t[-1, -2, -1],\n",
    "\t[0, 0, 0],\n",
    "\t[1, 2, 1]), dtype=\"int\")\n",
    "# construct the kernel bank, a list of kernels we're going\n",
    "# to apply using both our custom `convole` function and\n",
    "# OpenCV's `filter2D` function\n",
    "kernelBank = (\n",
    "\t(\"small_blur\", smallBlur),\n",
    "\t'''(\"large_blur\", largeBlur),\n",
    "\t(\"sharpen\", sharpen),\n",
    "\t(\"laplacian\", laplacian),\n",
    "\t(\"sobel_x\", sobelX),\n",
    "\t(\"sobel_y\", sobelY)''')\n",
    "\n",
    "# load the input image and convert it to grayscale\n",
    "image = cv2.imread('messi.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# loop over the kernels\n",
    "for (kernelName, kernel) in kernelBank:\n",
    "\t# apply the kernel to the grayscale image using both\n",
    "\t# our custom `convole` function and OpenCV's `filter2D`\n",
    "\t# function\n",
    "\tprint(\"[INFO] applying {} kernel\".format(kernelName))\n",
    "\tconvoleOutput = convolve(gray, kernel, 0, 2)\n",
    "\topencvOutput = cv2.filter2D(gray, -1, kernel)\n",
    " \n",
    "\t# show the output images\n",
    "\tcv2.imshow(\"original\", gray)\n",
    "\tcv2.imshow(\"{} - convole\".format(kernelName), convoleOutput)\n",
    "\tcv2.imshow(\"{} - opencv\".format(kernelName), opencvOutput)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6587c485f246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# load the image as RGB (3 channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCBGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# The edge detection kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "def convolution2d(conv_input, conv_kernel, strides=(1, 1), padding='same'):\n",
    "    # This function which takes an input (Tensor) and a kernel (Tensor)\n",
    "    # and returns the convolution of them\n",
    "    # Args:\n",
    "    #   conv_input: a numpy array of size [input_height, input_width, input # of channels].\n",
    "    #   conv_kernel: a numpy array of size [kernel_height, kernel_width, input # of channels]\n",
    "    #                represents the kernel of the Convolutional Layer's filter.\n",
    "    #   bias: a scalar value, represents the bias of the Convolutional Layer's filter.\n",
    "    #   strides: a tuple of (convolution vertical stride, convolution horizontal stride).\n",
    "    #   padding: type of the padding scheme: 'same' or 'valid'.\n",
    "    # Returns:\n",
    "    #   a numpy array (convolution output).\n",
    "\n",
    "    assert len(conv_kernel.shape) == 3, \"The size of the kernel should be (kernel_height, kernel_width, input # of channels)\"\n",
    "    assert len(conv_input.shape) == 3, \"The size of the input should be (input_height, input_width, input # of channels)\"\n",
    "    assert conv_kernel.shape[2] == conv_input.shape[2], \"the input and the kernel should have the same depth.\"\n",
    "\n",
    "    input_w, input_h = conv_input.shape[1], conv_input.shape[0]      # input_width and input_height\n",
    "    kernel_w, kernel_h = conv_kernel.shape[1], conv_kernel.shape[0]  # kernel_width and kernel_height\n",
    "\n",
    "    if padding == 'same':\n",
    "        output_height = int(ceil(float(input_h) / float(strides[0])))\n",
    "        output_width = int(ceil(float(input_w) / float(strides[1])))\n",
    "\n",
    "        # Calculate the number of zeros which are needed to add as padding\n",
    "        pad_along_height = max((output_height - 1) * strides[0] + kernel_h - input_h, 0)\n",
    "        pad_along_width = max((output_width - 1) * strides[1] + kernel_w - input_w, 0)\n",
    "        pad_top = pad_along_height // 2             # amount of zero padding on the top\n",
    "        pad_bottom = pad_along_height - pad_top     # amount of zero padding on the bottom\n",
    "        pad_left = pad_along_width // 2             # amount of zero padding on the left\n",
    "        pad_right = pad_along_width - pad_left      # amount of zero padding on the right\n",
    "\n",
    "        output = np.zeros((output_height, output_width))  # convolution output\n",
    "\n",
    "        # Add zero padding to the input image\n",
    "        image_padded = np.zeros((conv_input.shape[0] + pad_along_height,\n",
    "                                 conv_input.shape[1] + pad_along_width, conv_input.shape[2]))\n",
    "        image_padded[pad_top:-pad_bottom, pad_left:-pad_right, :] = conv_input\n",
    "\n",
    "        for x in range(output_width):  # Loop over every pixel of the output\n",
    "            for y in range(output_height):\n",
    "                # element-wise multiplication of the kernel and the image\n",
    "                output[y, x] = (conv_kernel * image_padded[y * strides[0]:y * strides[0] + kernel_h,\n",
    "                                x * strides[1]:x * strides[1] + kernel_w, :]).sum()\n",
    "\n",
    "    elif padding == 'valid':\n",
    "        output_height = int(ceil(float(input_h - kernel_h + 1) / float(strides[0])))\n",
    "        output_width = int(ceil(float(input_w - kernel_w + 1) / float(strides[1])))\n",
    "\n",
    "        output = np.zeros((output_height, output_width))  # convolution output\n",
    "\n",
    "        for x in range(output_width):  # Loop over every pixel of the output\n",
    "            for y in range(output_height):\n",
    "                # element-wise multiplication of the kernel and the image\n",
    "                output[y, x] = (conv_kernel * conv_input[y * strides[0]:y * strides[0] + kernel_h,\n",
    "                                x * strides[1]:x * strides[1] + kernel_w, :]).sum()\n",
    "\n",
    "    return output\n",
    "\n",
    "# load the image as RGB (3 channels)\n",
    "img = cv2.cvtColor('image', CBGR2RGB)\n",
    "\n",
    "# The edge detection kernel\n",
    "kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])[..., None]\n",
    "kernel = np.repeat(kernel, 3, axis=2)\n",
    "\n",
    "# Convolve image and kernel\n",
    "image_edges= convolution2d(img, kernel)\n",
    "\n",
    "# Plot the filtered image\n",
    "plt.imshow(image_edges, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Adjust the contrast of the filtered image by applying Histogram Equalization\n",
    "image_edges_equalized = exposure.equalize_adapthist(image_edges / np.max(np.abs(image_edges)),\n",
    "                                                      clip_limit=0.03)\n",
    "plt.imshow(image_edges_equalized, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
